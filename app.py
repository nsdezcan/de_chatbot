import streamlit as st
import os
import requests
from bs4 import BeautifulSoup
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import google.generativeai as genai

# -------------------------------------------------
# 1. SAYFA KONFÄ°GÃœRASYONU VE STÄ°L
# -------------------------------------------------
st.set_page_config(page_title="Karriere-Chatbot", page_icon="ğŸ¤–", layout="wide")

# Google Drive yollarÄ± kaldÄ±rÄ±ldÄ±, yerine gÃ¶reli (relative) yollar eklendi.
# Bu dosyalarÄ±n "assets" adÄ±nda bir klasÃ¶rde olduÄŸunu varsayÄ±yoruz.
LOGO_BA_PATH = "assets/logo_ba.png"
LOGO_COMPANY_PATH = "assets/logo_company.png"

def set_styles():
    st.markdown("""
        <style>
        .stApp { background-color: #f0f2f6; }
        [data-testid="chat-messages"] { background-color: #ffffff; }
        [data-testid="stSidebar"] { background-color: #ffffff; }
        .st-emotion-cache-16txtl3 { padding-top: 2rem; }
        </style>
    """, unsafe_allow_html=True)

set_styles()

# -------------------------------------------------
# 2. DÄ°L VE METÄ°N YÃ–NETÄ°MÄ°
# -------------------------------------------------
LANGUAGES = {
    "Deutsch": {
        "page_title": "Karriere-Chatbot",
        "sidebar_title": "Einstellungen",
        "main_title": "Agentur fÃ¼r Arbeit",
        "main_subtitle": "Karriere-Assistent",
        "chat_placeholder": "Stellen Sie hier Ihre Frage...",
        "language_select": "Sprache",
        "welcome_message": "Hallo! Wie kann ich Ihnen bei Ihrer Karriereplanung helfen?",
        "error_key": "Gemini API-SchlÃ¼ssel nicht gefunden. Bitte fÃ¼gen Sie ihn in der Seitenleiste hinzu.",
        "info_source": "Quelle",
        "no_vector": "ğŸ“¦ Vectorstore nicht gefunden. Ich antworte nur mit LLM.",
    },
    "English": {
        "page_title": "Career Chatbot",
        "sidebar_title": "Settings",
        "main_title": "Federal Employment Agency",
        "main_subtitle": "Career Assistant",
        "chat_placeholder": "Ask your question here...",
        "language_select": "Language",
        "welcome_message": "Hello! How can I assist you with your career planning today?",
        "error_key": "Gemini API key not found. Please add it in the sidebar.",
        "info_source": "Source",
        "no_vector": "ğŸ“¦ Vectorstore not found. I will answer only with LLM.",
    },
}

# -------------------------------------------------
# 3. CHATBOT Ã‡EKÄ°RDEK FONKSÄ°YONLARI
# -------------------------------------------------

@st.cache_resource
def get_embeddings_model():
    """Embedding modelini bir kez yÃ¼kler ve cache'ler."""
    return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

@st.cache_resource
def load_vectorstore(_embeddings):
    """VektÃ¶r veritabanÄ±nÄ± bir kez yÃ¼kler ve cache'ler."""
    
    # Google Drive yolu kaldÄ±rÄ±ldÄ±, "vectorstore" klasÃ¶rÃ¼nÃ¼n ana dizinde olduÄŸunu varsayÄ±yoruz.
    vectorstore_path = "vectorstore" 
    
    if os.path.exists(vectorstore_path):
        return FAISS.load_local(
            vectorstore_path,
            _embeddings,
            allow_dangerous_deserialization=True, # GÃ¼venlik uyarÄ±sÄ± iÃ§in bu parametre gerekli
        )
    return None

def get_context_from_vectorstore(vectorstore, question, k=4):
    """Soruyu vektÃ¶r veritabanÄ±nda arar ve ilgili context'i dÃ¶ndÃ¼rÃ¼r."""
    if vectorstore is None:
        return "", []
    retriever = vectorstore.as_retriever(search_kwargs={"k": k})
    docs = retriever.get_relevant_documents(question)
    context_text = "\n\n".join([d.page_content for d in docs])
    return context_text, docs

def ask_gemini(gemini_api_key: str, question: str, context: str) -> str:
    """Gemini modeline context ile birlikte soruyu sorar."""
    
    # API anahtarÄ± yoksa ortam deÄŸiÅŸkeninden (Secrets) almayÄ± dener
    if not gemini_api_key:
        gemini_api_key = os.getenv("GEMINI_API_KEY")

    if not gemini_api_key:
        return "Hata: Gemini API anahtarÄ± bulunamadÄ±."

    try:
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")

        prompt = f"""
    You are a helpful assistant. Use the context below to answer the question.
    If the answer is not in the context, say you don't know.

    CONTEXT:
    {context}

    QUESTION:
    {question}
    """
        resp = model.generate_content(prompt)
        return resp.text
    except Exception as e:
        st.error(f"Gemini API ile iletiÅŸimde bir hata oluÅŸtu: {str(e)}")
        return "Bir hata nedeniyle cevap veremiyorum."

# -------------------------------------------------
# 4. STREAMLIT ARAYÃœZÃœ
# -------------------------------------------------

# API AnahtarÄ±nÄ± Streamlit Secrets'tan (ortam deÄŸiÅŸkeni) okumayÄ± dener
api_key_from_env = os.getenv("GEMINI_API_KEY")

if "language" not in st.session_state:
    st.session_state.language = "Deutsch"

texts = LANGUAGES[st.session_state.language]

with st.sidebar:
    if os.path.exists(LOGO_COMPANY_PATH):
        st.image(LOGO_COMPANY_PATH, width=150)
    st.title(texts["sidebar_title"])

    selected_language = st.selectbox(
        texts["language_select"],
        options=list(LANGUAGES.keys()),
        index=0 if st.session_state.language == "Deutsch" else 1,
    )
    if selected_language != st.session_state.language:
        st.session_state.language = selected_language
        st.rerun()

    # KullanÄ±cÄ±nÄ±n manuel API anahtarÄ± girmesine izin verir
    # VarsayÄ±lan deÄŸer olarak Secrets'tan okunan anahtarÄ± kullanÄ±r
    gemini_api_key = st.text_input(
        "Gemini API Key", type="password", value=api_key_from_env or ""
    )

col1, col2 = st.columns([1, 4])
with col1:
    if os.path.exists(LOGO_BA_PATH):
        st.image(LOGO_BA_PATH, width=150)
with col2:
    st.title(texts["main_title"])
    st.subheader(texts["main_subtitle"])

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": texts["welcome_message"]}
    ]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

prompt = st.chat_input(texts["chat_placeholder"])

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    if not gemini_api_key:
        with st.chat_message("assistant"):
            st.error(texts["error_key"])
    else:
        # Modelleri ve veritabanÄ±nÄ± yÃ¼kle (cache sayesinde hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r)
        try:
            embeddings = get_embeddings_model()
            vectorstore = load_vectorstore(embeddings)
        except Exception as e:
            vectorstore = None
            st.error(f"VektÃ¶r veritabanÄ± yÃ¼klenirken hata oluÅŸtu: {e}")

        # Context'i al
        if vectorstore:
            with st.spinner("DokÃ¼manlar aranÄ±yor..."):
                context_text, _ = get_context_from_vectorstore(vectorstore, prompt)
        else:
            context_text = ""
            st.info(texts["no_vector"])

        # Gemini'den cevabÄ± al
        answer = ask_gemini(gemini_api_key, prompt, context_text)
        with st.chat_message("assistant"):
            st.markdown(answer)
        st.session_state.messages.append({"role": "assistant", "content": answer})
